package io.frictionlessdata.tableschema.datasourceformat;

import io.frictionlessdata.tableschema.exception.TableSchemaException;
import org.apache.commons.csv.CSVFormat;
import org.apache.commons.csv.CSVParser;
import org.apache.commons.csv.CSVPrinter;
import org.json.CDL;
import org.json.JSONArray;
import org.json.JSONObject;

import java.io.*;
import java.nio.charset.StandardCharsets;
import java.util.stream.Collectors;

/**
 *
 */
public class JsonArrayDataSourceFormat extends AbstractDataSourceFormat {

    public JsonArrayDataSourceFormat(String json){
        super();
        this.dataSource = new JSONArray(DataSourceFormat.trimBOM(json));
    }

    public JsonArrayDataSourceFormat (InputStream inStream) throws IOException {
        try (InputStreamReader inputStreamReader = new InputStreamReader(inStream, StandardCharsets.UTF_8);
        BufferedReader br = new BufferedReader(inputStreamReader)) {
            String content = br.lines().collect(Collectors.joining("\n"));
            this.dataSource = new JSONArray(DataSourceFormat.trimBOM(content));
        }
    }

    /**
     * Write as CSV file, the `format` parameter decides on the CSV options. If it is
     * null, then the file will be written as RFC 4180 compliant CSV
     * @param out the Writer to write to
     * @param format the CSV format to use
     * @param sortedHeaders the header row names in the order in which data should be
     *                      exported
     */
    @Override
    public void writeCsv(Writer out, CSVFormat format, String[] sortedHeaders) {
        if (null == sortedHeaders) {
            throw new TableSchemaException("Json array-based tables must have externally set headers");
        }
        try {
            CSVFormat locFormat = (null != format)
                    ? format
                    : DataSourceFormat.getDefaultCsvFormat();

            locFormat = locFormat.withHeader(sortedHeaders);
            CSVPrinter csvPrinter = new CSVPrinter(out, locFormat);
            JSONArray data = (JSONArray)this.dataSource;
            for (Object record : data) {
                JSONObject obj = (JSONObject) record;
                writeDataRow(obj, sortedHeaders, csvPrinter);
            }
            csvPrinter.close();
        } catch (Exception ex) {
            throw new RuntimeException(ex);
        }
    }

    private static void writeDataRow(JSONObject data, String[] sortedHeaders, CSVPrinter csvPrinter) {
        try {
            int recordLength = sortedHeaders.length;
            String[] sortedRec = new String[recordLength];
            for (int i = 0; i < recordLength; i++) {
                String key = sortedHeaders[i];
                if (data.has(key))
                    sortedRec[i] = data.get(key).toString();
            }
            csvPrinter.printRecord(sortedRec);
        } catch (Exception ex) {
            throw new RuntimeException(ex);
        }
    }

    @Override
    public void write(File outputFile) throws Exception {
        try (Writer out = new BufferedWriter(new FileWriter(outputFile))) {
            out.write(dataSource.toString());
        } catch (Exception e) {
            throw e;
        }
    }

    @Override
    public boolean hasReliableHeaders() {
        return false;
    }

    /**
     * Retrieve the CSV Parser.
     *
     *
     * @return a CSVParser instance that works CSV data generated by converting the JSON-array data to CSV
     * @throws Exception thrown if the parser throws an exception
     */
    @Override
    CSVParser getCSVParser() throws Exception {
        String dataCsv = null;
        if(dataSource instanceof JSONArray){
            dataCsv = CDL.toString((JSONArray)dataSource);
        } else{
            throw new TableSchemaException("Data source is of invalid type.");
        }
        Reader sr = new StringReader(dataCsv);
        // Get the parser.
        return CSVParser.parse(sr, DataSourceFormat.getDefaultCsvFormat());
    }
}
